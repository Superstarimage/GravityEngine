
#include "StaticSamplers.hlsli"
#include "ShaderUtil.hlsli"
#include "ShaderDefinition.h"
#include "MainPassCB.hlsli"

#define DEBUG 0

#define NUM_RESOLVE 4
#define BRDF_BIAS 0.0f

#define FIRE_FLIES 1

#define USE_PREFILTER 1

struct VertexToPixel
{
	float4 position		: SV_POSITION;
	float2 uv           : TEXCOORD0;
};

// Input textures.
Texture2D gDepthTexture								: register(t0);
Texture2D gNormalTexture							: register(t1);
Texture2D gOrmTexture								: register(t2);
Texture2D gColorTexture								: register(t3);
Texture2D gBlueNoiseTexture							: register(t4);
Texture2D gRayTraceTexture							: register(t5);
Texture2D gRayTraceMaskTexture						: register(t6);

Texture2D gHiZTexture[SSR_MAX_MIP_LEVEL]			: register(t0, space1);

Texture2D gPrefilter[SSR_MAX_PREFILTER_LEVEL]		: register(t0, space2);

static const float2 offset[4] =
{
	float2(0, 0),
	float2(2, -2),
	float2(-2, -2),
	float2(0, 2)
};

float3 GetScreenPos(float2 uv, float depth)
{
	//return float3(uv.xy * 2 - 1, depth);
	return float3(uv.x * 2.0f - 1.0f, 1.0f - 2.0f * uv.y, depth);
}

float3 ReconstructWorldPos(float2 uv, float depth)
{
	float ndcX = uv.x * 2 - 1;
	float ndcY = 1 - uv.y * 2; // Remember to flip y!!!
	float4 viewPos = mul(float4(ndcX, ndcY, depth, 1.0f), gUnjitteredInvProj);
	viewPos = viewPos / viewPos.w;
	return mul(viewPos, gInvView).xyz;
}

float3 GetViewDir(float3 worldPos)
{
	return normalize(worldPos - gEyePosW);
}

float3 GetViewPos(float3 screenPos)
{
	float4 viewPos = mul(float4(screenPos, 1), gUnjitteredInvProj);
	return viewPos.xyz / viewPos.w;
}

float4 TangentToWorld(float3 N, float4 H)
{
	float3 UpVector = abs(N.z) < 0.999 ? float3(0.0, 0.0, 1.0) : float3(1.0, 0.0, 0.0);
	float3 T = normalize(cross(UpVector, N));
	float3 B = cross(N, T);

	return float4((T * H.x) + (B * H.y) + (N * H.z), H.w);
}

float Luminance(float3 color)
{
	return (0.587f * color.r + 0.114f * color.g + 0.299f * color.b);
}

// Brian Karis, Epic Games "Real Shading in Unreal Engine 4"
float4 ImportanceSampleGGX(float2 Xi, float Roughness)
{
	float m = Roughness * Roughness;
	float m2 = m * m;

	float Phi = 2 * _PI * Xi.x;

	float CosTheta = sqrt((1.0 - Xi.y) / (1.0 + (m2 - 1.0) * Xi.y));
	float SinTheta = sqrt(max(1e-5, 1.0 - CosTheta * CosTheta));

	float3 H;
	H.x = SinTheta * cos(Phi);
	H.y = SinTheta * sin(Phi);
	H.z = CosTheta;

	float d = (CosTheta * m2 - CosTheta) * CosTheta + 1;
	float D = m2 / (_PI * d * d);
	float pdf = D * CosTheta;

	return float4(H, pdf);
}

inline half SmithJointGGXVisibilityTerm(half NdotL, half NdotV, half roughness)
{
	half a = roughness;
	half lambdaV = NdotL * (NdotV * (1 - a) + a);
	half lambdaL = NdotV * (NdotL * (1 - a) + a);

	return 0.5f / (lambdaV + lambdaL + 1e-5f);
}

inline float GGXTerm(float NdotH, float roughness)
{
	float a2 = roughness * roughness;
	float d = (NdotH * a2 - NdotH) * NdotH + 1.0f; // 2 mad
	return a2 / (_PI * (d * d + 1e-7f)); // This function is not intended to be running on Mobile,
	// therefore epsilon is smaller than what can be represented by half
}

float BRDF_Weight(float3 V, float3 L, float3 N, float Roughness)
{
	float3 H = normalize(L + V);

	float NdotH = saturate(dot(N, H));
	float NdotL = saturate(dot(N, L));
	float NdotV = saturate(dot(N, V));

	half G = SmithJointGGXVisibilityTerm(NdotL, NdotV, Roughness);
	half D = GGXTerm(NdotH, Roughness);

	return (D * G) * (_PI / 4.0);
}

half4 main(VertexToPixel i) : SV_Target
{
	float2 uv = i.uv;
	float2 jitteredUV = uv + gJitter;

#if DEBUG
	float4 testHitPacked = gRayTraceTexture.SampleLevel(linearClampSampler, uv, 0.0f);
	float hitMask = gRayTraceMaskTexture.SampleLevel(linearClampSampler, uv, 0.0f).r;
	//return gColorTexture.SampleLevel(linearClampSampler, testHitPacked.xy + gJitter, 0.0f);
	//return float4(hitMask.rrr, 1.0f);
	if (hitMask >= 0.5f)
		return gColorTexture.SampleLevel(linearClampSampler, testHitPacked.xy + gJitter, 0.0f);
	return float4(0.0f, 0.0f, 0.0f, 1.0f);
#endif

	float depth = gDepthTexture.SampleLevel(linearClampSampler, jitteredUV, 0.0f).r;
	float roughness = clamp(gOrmTexture.SampleLevel(linearClampSampler, jitteredUV, 0.0f).g, 0.03f, 1.00f);
	float3 worldNormal = gNormalTexture.SampleLevel(linearClampSampler, jitteredUV, 0.0f).rgb;
	float3 viewNormal = normalize(mul(worldNormal, (half3x3)gView));

	float3 screenPos = GetScreenPos(uv, depth);
	float3 worldPos = ReconstructWorldPos(uv, depth);
	float3 viewPos = GetViewPos(screenPos);
	float3 viewDir = GetViewDir(worldPos);

	// Blue noise generated by https://github.com/bartwronski/BlueNoiseGenerator/
	float2 blueNoise = gBlueNoiseTexture.SampleLevel(linearWrapSampler, (uv + gHaltonUniform2D.xy) * (gRenderTargetSize.xy) / float2(BLUE_NOISE_SIZE, BLUE_NOISE_SIZE), 0.0f).rg * 2.0 - 1.0; // works better with [-1, 1] range
	float2x2 offsetRotationMatrix = float2x2(blueNoise.x, blueNoise.y, -blueNoise.y, blueNoise.x);

	/*
	float2x2 offsetRotationMatrix;
	{
		float2 offsetRotation;
		sincos(2.0 * PI * InterleavedGradientNoise(pos, 0.0), offsetRotation.y, offsetRotation.x);
		offsetRotationMatrix = float2x2(offsetRotation.x, offsetRotation.y, -offsetRotation.y, offsetRotation.x);
	}
	*/

	//float NdotV = saturate(dot(worldNormal, -viewDir));
	float NdotV = saturate(dot(viewNormal, -viewDir));
	float coneTangent = lerp(0.0, roughness * (1.0 - BRDF_BIAS), NdotV * sqrt(roughness));

	float maxMipLevel = (float)SSR_MAX_MIP_LEVEL - 1.0;

	float4 result = 0.0;
	float weightSum = 0.0;
	for (int i = 1; i < NUM_RESOLVE; i++)
	{
		float2 offsetUV = offset[i] * (1.0 / gRenderTargetSize.xy);
		offsetUV = mul(offsetUV, offsetRotationMatrix);

		// "uv" is the location of the current (or "local") pixel. We want to resolve the local pixel using
		// intersections spawned from neighboring pixels. The neighboring pixel is this one:
		float2 neighborUv = uv + offsetUV;

		// Now we fetch the intersection point and the PDF that the neighbor's ray hit.
		float4 hitPacked = gRayTraceTexture.SampleLevel(linearClampSampler, neighborUv, 0.0f);
		float2 hitUv = hitPacked.xy;
		float hitZ = hitPacked.z;
		float hitPDF = hitPacked.w;
		float hitMask = gRayTraceMaskTexture.SampleLevel(linearClampSampler, neighborUv, 0.0f).r;

		float3 hitViewPos = GetViewPos(GetScreenPos(hitUv, hitZ));

		// We assume that the hit point of the neighbor's ray is also visible for our ray, and we blindly pretend
		// that the current pixel shot that ray. To do that, we treat the hit point as a tiny light source. To calculate
		// a lighting contribution from it, we evaluate the BRDF. Finally, we need to account for the probability of getting
		// this specific position of the "light source", and that is approximately 1/PDF, where PDF comes from the neighbor.
		// Finally, the weight is BRDF/PDF. BRDF uses the local pixel's normal and roughness, but PDF comes from the neighbor.
		float weight = BRDF_Weight(normalize(-viewPos) /*V*/, normalize(hitViewPos - viewPos) /*L*/, viewNormal /*N*/, roughness) / max(1e-5, hitPDF);

		float4 sampleColor = float4(0.0, 0.0, 0.0, 1.0);
#if USE_PREFILTER
		float intersectionCircleRadius = coneTangent * length(hitUv - uv);
		float mip = clamp(log2(intersectionCircleRadius * max(gRenderTargetSize.x, gRenderTargetSize.y)), 0.0, SSR_MAX_PREFILTER_LEVEL);
		if (mip == 0)
			sampleColor.rgb = gColorTexture.Sample(linearClampSampler, hitUv, 0.0f).rgb;
		else
			sampleColor.rgb = gPrefilter[mip - 1].Sample(linearClampSampler, hitUv, 0.0f).rgb;
		//sampleColor.a = RayAttenBorder(hitUv, _EdgeFactor) * hitMask;
		sampleColor.a = hitMask;
#else
		sampleColor = gColorTexture.SampleLevel(linearClampSampler, hitUv + gJitter, 0.0f);
		sampleColor.a = hitMask;
#endif

#if FIRE_FLIES
		sampleColor.rgb /= 1 + Luminance(sampleColor.rgb);
#endif

		result += sampleColor * weight;
		weightSum += weight;
	}
	result /= weightSum;

#if FIRE_FLIES
	result.rgb /= 1 - Luminance(result.rgb);
#endif

	//return max(result, 1e-5);

	//return float4(saturate(weightSum.rrr), 1.0f);
	if (result.a > 0.01f)
		return max(result, 1e-5);
	return float4(0.0f, 0.0f, 0.0f, 0.0f);
}

